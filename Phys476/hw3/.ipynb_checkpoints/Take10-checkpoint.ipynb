{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those who are trying to recreate/use this program with TF 1.0 have following changes to do:\n",
    "\n",
    "--> import input_data\n",
    "<> from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "--> tf.histogram_summary(\"weights\", W)\n",
    "<> tf.summary.histogram(name, value, collections = none)\n",
    "\n",
    "--> tf.scalar_summary(\"cost_function\", cost_function)\n",
    "<> tf.summary.scalar(name, tensor, collection = none)\n",
    "\n",
    "--> tf.initialize_all_variables()\n",
    "<> tf.global_variables_initializer()\n",
    "\n",
    "--> tf.merge_all_summaries()\n",
    "<> tf.summary.merge_all()\n",
    "\n",
    "--> tf.train.SummaryWriter('LOCATION\", graph_def = sess.graph_def)\n",
    "<> tf.summary.FileWriter('LOCATION', sess.graph)ï»¿\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cancer.dat', header = None, names = ['ID', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli','Mitoses','Class'],skiprows=[23,40,139,145,158,164,235,249,275,292,294,297,315,321,411,617]) \n",
    "X = data.values[:,1:10]\n",
    "y = pd.get_dummies(data['Class']).values\n",
    "X_train, X_test, y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "learning_rate = 0.01\n",
    "training_iteration = 30\n",
    "batch_size = 100\n",
    "display_step = 2\n",
    "num_inputs = len(X[0])\n",
    "num_labels = len(y[0])\n",
    "# TF graph input\n",
    "x = tf.placeholder(\"float\", [None, num_inputs]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(\"float\", [None, num_labels]) # 0-9 digits recognition => 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([num_inputs, num_labels]))\n",
    "b = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "with tf.name_scope(\"Wx_b\") as scope:\n",
    "    # Construct a linear model\n",
    "    model = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "    \n",
    "# Add summary ops to collect data\n",
    "w_h = tf.summary.histogram(\"weights\", W)\n",
    "b_h = tf.summary.histogram(\"biases\", b)\n",
    "\n",
    "# More name scopes will clean up graph representation\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    # Minimize error using cross entropy\n",
    "    # Cross entropy\n",
    "    cost_function = -tf.reduce_sum(y*tf.log(model))\n",
    "    # Create a summary to monitor the cost function\n",
    "    tf.summary.scalar(\"cost_function\", cost_function)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    # Gradient descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-754855f24875>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-754855f24875>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    print \"Iteration:\", '%04d' % (iteration + 1), \"cost=\", \"{:.9f}\".format(avg_cost)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "# Merge all summaries into a single operator\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Change this to a location on your computer\n",
    "    summary_writer = tf.summary.FileWriter('.', sess.graph)\n",
    "\n",
    "    # Training cycle\n",
    "    for iteration in range(training_iteration):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Compute the average loss\n",
    "            avg_cost += sess.run(cost_function, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "            # Write logs for each iteration\n",
    "            summary_str = sess.run(merged_summary_op, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            summary_writer.add_summary(summary_str, iteration*total_batch + i)\n",
    "        # Display logs per iteration step\n",
    "        if iteration % display_step == 0:\n",
    "            print \"Iteration:\", '%04d' % (iteration + 1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Tuning completed!\"\n",
    "\n",
    "    # Test the model\n",
    "    predictions = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions, \"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
