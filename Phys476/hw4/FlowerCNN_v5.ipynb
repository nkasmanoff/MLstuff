{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will construct a CNN within tensorflow to identify the type of flower, won't actually be running this code here though becuase it requires a GPU, so that'll happen on a remote server but let's get the basics down here!\n",
    "\n",
    "\n",
    "https://www.kaggle.com/alxmamaev/flowers-recognition\n",
    "\n",
    "Should now only read in jpegs\n",
    "\n",
    "Running cnn now, building/fixing architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part I\n",
    "------\n",
    "Making the dataset\n",
    "\n",
    "Here I'm making the arrays of each flower type, defining their label, and then making a function to find the max height and width.\n",
    "\n",
    "Not sure how to find the \"nominal\" height and width, but the code to find it is in here provided you know what you're looking for (I don't). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making my daisy set in here\n",
    "\n",
    "X_daisies = []\n",
    "y_daisies = []\n",
    "for file in os.listdir('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/daisy'):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        img = cv2.imread('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/daisy/' + file)\n",
    "        X_daisies.append(img)\n",
    "        y_daisies.append([np.float64(1),np.float64(0),np.float64(0),np.float64(0),np.float64(0)])\n",
    "\n",
    "        \n",
    "        \n",
    "#Now for dandelions\n",
    "X_dandelions = []\n",
    "y_dandelions = []\n",
    "for file in os.listdir('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/dandelion'):\n",
    "    #print(filename)\n",
    "    if file.endswith(\".jpg\"):\n",
    "        img = cv2.imread('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/dandelion/' + file)\n",
    "        X_dandelions.append(img)\n",
    "        y_dandelions.append([np.float64(0),np.float64(1),np.float64(0),np.float64(0),np.float64(0)])\n",
    "\n",
    "#Now for roses\n",
    "X_roses = []\n",
    "y_roses = []\n",
    "for file in os.listdir('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/rose'):\n",
    "    #print(filename)\n",
    "    if file.endswith(\".jpg\"):\n",
    "        img = cv2.imread('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/rose/' + file)\n",
    "        X_roses.append(img)\n",
    "        y_roses.append([np.float64(0),np.float64(0),np.float64(1),np.float64(0),np.float64(0)])\n",
    "\n",
    "#Now for sunflowers\n",
    "X_sunflowers = []\n",
    "y_sunflowers = []\n",
    "for file in os.listdir('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/sunflower'):\n",
    "    #print(filename)\n",
    "    if file.endswith(\".jpg\"):\n",
    "        img = cv2.imread('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/sunflower/' + file)\n",
    "        X_sunflowers.append(img)\n",
    "        y_sunflowers.append([np.float64(0),np.float64(0),np.float64(0),np.float64(1),np.float64(0)])\n",
    "\n",
    "#Last but not least, tulips\n",
    "X_tulips = []\n",
    "y_tulips = []\n",
    "for file in os.listdir('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/tulip'):\n",
    "    #print(filename)\n",
    "    if file.endswith(\".jpg\"):\n",
    "        img = cv2.imread('/Users/noahkasmanoff/MachLearn/Phys476/hw4/flowers/tulip/' + file)\n",
    "        X_tulips.append(img)\n",
    "        y_tulips.append([np.float64(0),np.float64(0),np.float64(0),np.float64(0),np.float64(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've now created arrays for each of the flowers, now merging them all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merging all at once. 4236 flowers in all. \n",
    "\n",
    "X_args = (X_daisies,X_dandelions,X_roses,X_sunflowers,X_tulips)\n",
    "y_args = (y_daisies,y_dandelions,y_roses,y_sunflowers,y_tulips)\n",
    "X_flowers = np.concatenate(X_args)\n",
    "y_flowers = np.concatenate(y_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "def resize_with_pad(img, img_size):\n",
    "    height, width, _ = img.shape\n",
    "    ratio = img_size / max(height, width)\n",
    "   # print(ratio)\n",
    "    if ratio < 1:\n",
    "        img = cv2.resize(img, (int(ratio * width), int(ratio * height)))\n",
    "    padding = ((img_size - img.shape[0], 0), (img_size - img.shape[1],0), (0,0))\n",
    "\n",
    "    return np.pad(img, padding, 'constant')\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "for i in range(0,len(X_flowers)):\n",
    "    \n",
    "    X_flowers[i] = resize_with_pad(X_flowers[i], 28)\n",
    "    X_flowers[i] = rgb2gray(X_flowers[i])\n",
    "   # X_flowers[i] = np.array(X_flowers[i]).reshape(1, 360,360,3) useless!\n",
    "    #Extra line here reshapes to accept batch size as a dimension of accepted pics at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_flowers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in range(0,len(X_flowers)):\n",
    "    X_flowers[j] = (X_flowers[j]).flatten()/255\n",
    "    X_flowers[j] = np.array(X_flowers[j],dtype='float32')\n",
    "    #Float 32 conversion\n",
    "    \n",
    "\n",
    "\n",
    "  #  y_flowers[k] = np.array(y_flowers[k],dtype='float32')\n",
    "    #Change each element\n",
    "    #Float 32 conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_flowers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flowers, y_flowers, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the block below we can identify shitty data. Delete here. \n",
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really sure what this error is, probs worth investigating, but it looks like the max height is 640. Keep in mind this data set isn't clean, there's like a python script inside it and otehr things that could explain this issue and will go away once removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(np.float32(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making this data set the rest is using a CNN which is conveniently explained how to make below!\n",
    "\n",
    "\n",
    "So basically the cells above convert this into an array, (1066, 1599, 3)  3 representing RGB vals, so that's on track with this flower recog software\n",
    "\n",
    "Next up is to design the CNN... \n",
    "\n",
    "Pulling from Aymerican Dreams...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(X_flowers[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#should convert vals to float 32, will get on that later.\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batch_size = 10\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_inputs = 28*28\n",
    "num_classes = 5 #total flower classes, daisy, etc. 5 total \n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "#X = tf.placeholder(tf.float32, [None, num_input])\n",
    "X = tf.placeholder(tf.float32,[None, num_inputs]) #28 * 28 taille image 1 = 1pixel car noir et blanc \"X\" valeur\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "360*360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 28,28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7*7*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = next_batch(batch_size,X_train,y_train)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x,\n",
    "                                      Y: batch_y,\n",
    "                                      keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test,\n",
    "                                      Y: y_test,\n",
    "                                      keep_prob: dropout}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14400.0/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
