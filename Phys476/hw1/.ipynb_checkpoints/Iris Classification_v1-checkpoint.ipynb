{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data taken from http://archive.ics.uci.edu/ml/datasets/Iri, basically takes an input of 4 or 5 vals, and classifies them as a certain kind of iris. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "np.random.seed(7) #why random?  for reproducability ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(a):\n",
    "    #Very temporary code since I don't know how to do this using pandas or numpy explicitly\n",
    "    #idea here is I will be splitting the data into training and testing segments. \n",
    "    atrain1,atrain2,atest = np.array_split(a,indices_or_sections=3)\n",
    "    atrain = np.concatenate(atrain1,atrain2)\n",
    "    \n",
    "    return atrain, atest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('iris.dat', header = None, names = ['sepal length','sepal width','petal length','petal width','class']) \n",
    "y = data['class'].values\n",
    "del data['class']\n",
    "\n",
    "x = data.values #once you remove the last column, this means everything else is the input data. \n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_all = []\n",
    "for i in range(len(y)):\n",
    "    if y[i] =='Iris-setosa':\n",
    "        y_all.append(0)\n",
    "    elif y[i] =='Iris-versicolor':\n",
    "        y_all.append(1)\n",
    "    elif  y[i] =='Iris-virginica':\n",
    "        y_all.append(2)\n",
    "        \n",
    "#now make it a numpy array\n",
    "\n",
    "y_all = np.array(y_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary = to_categorical(y_all)\n",
    "np.shape(y_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need to split into training and testing. Just do valiadation for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=4,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things I need to do to this data:\n",
    "\n",
    "Convert class into a 0,1,or 2\n",
    "\n",
    "This is a classification problem. \n",
    "Sequential model should be fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 0s 353us/step - loss: 1.0422 - val_loss: 1.1595\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 210us/step - loss: 1.0372 - val_loss: 1.1769\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 166us/step - loss: 1.0311 - val_loss: 1.1934\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 165us/step - loss: 1.0248 - val_loss: 1.2060\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 156us/step - loss: 1.0184 - val_loss: 1.2197\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 152us/step - loss: 1.0112 - val_loss: 1.2324\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 157us/step - loss: 1.0034 - val_loss: 1.2430\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 151us/step - loss: 0.9959 - val_loss: 1.2625\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 165us/step - loss: 0.9876 - val_loss: 1.2823\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 164us/step - loss: 0.9783 - val_loss: 1.2949\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 156us/step - loss: 0.9694 - val_loss: 1.3120\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.9600 - val_loss: 1.3169\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 157us/step - loss: 0.9498 - val_loss: 1.3331\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.9399 - val_loss: 1.3497\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 157us/step - loss: 0.9322 - val_loss: 1.3643\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 170us/step - loss: 0.9243 - val_loss: 1.3748\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 160us/step - loss: 0.9160 - val_loss: 1.3761\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.9092 - val_loss: 1.3954\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.9005 - val_loss: 1.4007\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 169us/step - loss: 0.8920 - val_loss: 1.3954\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 162us/step - loss: 0.8839 - val_loss: 1.3989\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 161us/step - loss: 0.8764 - val_loss: 1.4068\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 165us/step - loss: 0.8680 - val_loss: 1.4078\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 121us/step - loss: 0.8601 - val_loss: 1.4086\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 143us/step - loss: 0.8519 - val_loss: 1.4007\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.8443 - val_loss: 1.3959\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 155us/step - loss: 0.8371 - val_loss: 1.4010\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 151us/step - loss: 0.8300 - val_loss: 1.3959\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 172us/step - loss: 0.8235 - val_loss: 1.3865\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 144us/step - loss: 0.8173 - val_loss: 1.3877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1213bc978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y_binary,epochs=30,batch_size=20,validation_split=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all, y_strings = pd.factorize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_split(ary=[0,2.3,1],indices_or_sections=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
