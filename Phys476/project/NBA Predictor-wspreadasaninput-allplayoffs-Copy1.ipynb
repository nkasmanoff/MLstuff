{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have at my disposal the box score of every nba game since 2003. Planning to predict the winner, spread, and over under .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dependences\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense\n",
    "np.random.seed(7) #why random?\n",
    "from pandas import get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(FILENAME,sklearn=False,keras=False,normalize=True,overunder=False,spread=False,moneyline=False):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "    \"\"\"\n",
    "    Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and hot encoding is done. Other stuff too probably. Such as normalization, but I \n",
    "    didn't do that!\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \n",
    "    model : object\n",
    "        MLP which can predict the outcome of NBA games\n",
    "        \n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    #*retrospectively that doesn't make sense, could be worth changing!\n",
    "    data = read_csv(FILENAME) \n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values) \n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['Unnamed: 0'],data['GAME_ID'],data['Date'],data['Home'],data['Away'],data['PLUS_MINUS'],data['TOTAL']\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "\n",
    "    #print(data)\n",
    "    \n",
    "\n",
    "    dat = []\n",
    "    \n",
    "    #reshape the dataset so now each colummn has roadstats and homestats concatenated into the same row, used for NN \n",
    "    \n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "    \n",
    "    #convert list to array, now possible to array operations previously not possible\n",
    "    dat = np.array(dat)   \n",
    "    \n",
    "    openingspreadS = dat[:,8] #what the predicted spread of ther game was. \n",
    "    roadpts = dat[:,7]       #column of all the points scored by road team \n",
    "    homepts = dat[:,52]\n",
    "    endspreadS = roadpts-homepts  #all the final spreads of the game\n",
    "            #concatenating all the arrays, looks messy but explanation doen in another nb. \n",
    "    x1 = dat[:,0:7] #road offensive rebounds to blocks\n",
    "    x2 = dat[:,9:42] # road 3p% to team name (hot encoded)\n",
    "\n",
    "    x3 = dat[:,45:52] #home offensive rebounds to blocks\n",
    "    x4  =  dat[:,54:87] #home 3p% to hot encoded team name   \n",
    "                      \n",
    "    x5 = dat[:,8]              \n",
    "    X1 = np.concatenate((x1,x2),axis=1)\n",
    "    X2 = np.concatenate((x3,x4),axis=1)\n",
    "    X3 = np.concatenate((X1,X2),axis=1)\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    if overunder:\n",
    "        X = X3\n",
    "        #[OVER,PUSH,UNDER]\n",
    "        y = dat[:,42:45]\n",
    "        #save outcomes for all, easy to show over under. \n",
    "\n",
    "    \n",
    "    if spread:\n",
    "        #include initial spread of the game. \n",
    "        X = np.column_stack((X3,x5))\n",
    "\n",
    "        for j in range(len(endspreadS)):  \n",
    "            openspread = openingspreadS[j]\n",
    "       # print(\"this is the spread of the road team \" + str(openspread))\n",
    "            endspread = endspreadS[j]\n",
    "       # print(\"the road team won by  .. \" + str(endspread))\n",
    "       # if endspread>openspread:\n",
    "        #    y.append(np.array([0,1,0]))  #OK, now make sure this is formateed properly!\n",
    "            if openspread + endspread <0:\n",
    "                y.append(np.array([0,1,0]))  #home team covered\n",
    "            elif openspread + endspread >0:\n",
    "                y.append(np.array([1,0,0]))  #road covered\n",
    "            else: \n",
    "                y.append(np.array([0,0,1]))  #push!\n",
    "\n",
    "    \n",
    "    if moneyline:\n",
    "        X = X3\n",
    "        for j in range(len(endspreadS)):  \n",
    "            if endspreadS[j]<0:\n",
    "                #means the home team had more points\n",
    "                y.append(np.array([0,1]))\n",
    "            else:\n",
    "                y.append(np.array([1,0])) #alternatively, a road team victory. \n",
    "          \n",
    "\n",
    "    #Now I iterated over all these, and hot encoded the labels of each to see whether or not the spread was covered\n",
    "    #and by what team. \n",
    "\n",
    "\n",
    "        \n",
    "    y = np.array(y)  #same explanation as above\n",
    "                         \n",
    "    print(X[0])\n",
    "    print(np.shape(X))\n",
    "    #since everything got out of order I have to mash it together myself. \n",
    "    if normalize:\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        print(np.shape(X))\n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.27)\n",
    "    #print((X[0]))\n",
    "    #print(np.shape(X[0]))\n",
    "\n",
    "    #now to construct a model \n",
    "    if sklearn: \n",
    "        model = MLPClassifier()\n",
    "        model.shuffle = True\n",
    "        model.batch_size = 25\n",
    "    #model.n_layers_ = 1000000\n",
    "    #model.n_outputs_= 1000000\n",
    "    #These don't do anything, have to adjust the layers in some different way! Keras is useful for this.\n",
    "        model.fit(X_train,y_train)\n",
    "        print(model.score(X_test,y_test))\n",
    "    if keras:\n",
    "        print(\"keras NN goes here\")\n",
    "        model=Sequential()\n",
    "        model.add(Dense(22,input_dim=np.shape(X)[1],activation='relu'))\n",
    "        model.add(Dense(30,activation='relu'))\n",
    "        model.add(Dense(50,activation='relu'))\n",
    "        model.add(Dense(30,activation='relu'))\n",
    "        model.add(Dense(22,activation='relu'))\n",
    "\n",
    "        model.add(Dense(3,activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        model.fit(X_train,y_train,batch_size=40,epochs=20,validation_split=.2)\n",
    "        scores = model.evaluate(X_test,y_test)\n",
    "        print(scores[1])\n",
    "\n",
    "    \n",
    "    \n",
    "    return model,scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorOU,scaler = make_network('NBADATA.csv',sklearn=True,keras=False,normalize=True,overunder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorSPREAD,scaler = make_network('NBADATA.csv',sklearn=True,keras=False,normalize=True,spread=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorML,scaler = make_network('NBADATA.csv',sklearn=True,keras=False,normalize=True,moneyline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function I have is for turning the current nba team statistics (either over the entire season or some stretch) into an array of the same shape and information as the one used for the box scores above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_splits(TEAMABR,ten=False,twenty=False,regseason=True):\n",
    "    \"\"\"returns the splits of a team over the past N days. Will consider changing this to a from - to thing for different dates. \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from nba_py import team\n",
    "    teams = team.TeamList()\n",
    "    teamids = teams.info()\n",
    "    teamids = teamids[:-15]\n",
    "    teamids = teamids[['TEAM_ID','ABBREVIATION']]\n",
    "\n",
    "    teamids = teamids.rename(index=str, columns={\"ABBREVIATION\": \"Team\"})\n",
    "    teamids = teamids.replace('BKN','BRK')\n",
    "    teamids = teamids.sort_values('Team')\n",
    "\n",
    "    TEAM_ID = teamids.loc[teamids['Team'] == TEAMABR].values[0,0]\n",
    "    teamids = pd.get_dummies(teamids)\n",
    "    teamarray = teamids.loc[teamids['TEAM_ID'] == TEAM_ID].values[0,1:]\n",
    "\n",
    "\n",
    "    TEAM = team.TeamLastNGamesSplits(team_id=TEAM_ID)\n",
    "    if ten:\n",
    "        df = TEAM.last10()\n",
    "    if twenty:\n",
    "        df = TEAM.last20()\n",
    "    if regseason:\n",
    "        TEAM = team.TeamGeneralSplits(team_id=TEAM_ID)\n",
    "        df = TEAM.overall()\n",
    "   # if five:\n",
    "        #df = TEAM\n",
    "    \n",
    "    df = df[['OREB','DREB','REB','PF','STL','TOV','BLK','FG3_PCT','FG_PCT','FT_PCT']].values\n",
    "    \n",
    "    teamsplits = np.concatenate((df[0],teamarray))\n",
    "    return teamsplits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bos = get_splits('BOS')\n",
    "cle = get_splits('CLE')\n",
    "hou = get_splits('HOU')\n",
    "gsw = get_splits('GSW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_splits('BRK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OU_ML_game_maker(roadteam,hometeam,scaler):\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"\n",
    "        After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    game.append(spread)\n",
    "    game = [game]\n",
    "    game = scaler.transform(game)\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spread_game_maker(roadteam,hometeam,spread,scaler):\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"This includes the option to include the spread, which isn't the case for the other ones. \n",
    "    \n",
    "        After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    spread = np.array([spread])\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    game = np.concatenate((game,spread))\n",
    "    game = [game]\n",
    "    game = scaler.transform(game)\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clebos = game_maker(cle,bos,scaler)\n",
    "gswhou = spread_game_maker(gsw,hou,2,scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorOU.predict(gswhou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorML.predict(gswhou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorSPREAD.predict(gswhou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ This is differnet from the original prediction, which said it was going to be Golden State. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorOU.predict(clebos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorML.predict(clebos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictorSPREAD.predict(clebos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8+15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9+13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
