{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my most up to date and as annotated as possible script. For the data set, have it in you local directory (It's uploaded to github too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import dependences\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense\n",
    "np.random.seed(7) #why random?\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(FILENAME,sklearn=False,keras=False,normalize=True):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "    \"\"\"\n",
    "    Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and hot encoding is done. Other stuff too probably. Such as normalization, but I \n",
    "    didn't do that!\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \n",
    "    model : object\n",
    "        MLP which can predict the outcome of NBA games\n",
    "        \n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    data = read_csv(FILENAME) \n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values) \n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "    del data['VENUE']\n",
    "    #print(data)\n",
    "    \n",
    "\n",
    "    dat = []\n",
    "    \n",
    "    #reshape the dataset so now each colummn has roadstats and homestats concatenated into the same row, used for NN \n",
    "    \n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "    \n",
    "    #convert list to array, now possible to array operations previously not possible\n",
    "    dat = np.array(dat)   \n",
    "    \n",
    "    #now to find out the score of the game, and whether or not the spread was covered. \n",
    "    roadpts = dat[:,8] #column of all the points scored by road team \n",
    "    homepts = dat[:,21] #vice versa of above\n",
    "    #print(\"roadpts\",roadpts)\n",
    "    endspreadS = roadpts-homepts  #all the final spreads of the game\n",
    "    openingspreadS = dat[:,9]  #what the predicted spread of ther game was. \n",
    "    y = openingspreadS\n",
    "    print(y)\n",
    "    y = np.array(y)  #same explanation as above\n",
    "    X1 = np.concatenate((dat[:,0:8],dat[:,10:21]),axis=1)  #reshaping arrays,\n",
    "    #since everything got out of order I have to mash it together myself. \n",
    "    X = np.concatenate((X1,dat[:,23:26]),axis=1)    #need to go one further column to snag HFT% \n",
    "    if normalize:\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        \n",
    "\n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.27)\n",
    "    #print((X[0]))\n",
    "    #print(np.shape(X[0]))\n",
    "\n",
    "    #now to construct a model \n",
    "    if sklearn: \n",
    "        model = MLPRegressor()â€ \n",
    "        model.shuffle = True\n",
    "        model.batch_size = 25\n",
    "    #model.n_layers_ = 1000000\n",
    "    #model.n_outputs_= 1000000\n",
    "    #These don't do anything, have to adjust the layers in some different way! Keras is useful for this.\n",
    "        model.fit(X_train,y_train)\n",
    "        print(model.score(X_test,y_test))\n",
    "        \n",
    "    if keras:\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    \n",
    "    \n",
    "    return model,scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.   9.5 12.  ...  4.5 -9.   4.5]\n",
      "0.2986041258046618\n"
     ]
    }
   ],
   "source": [
    "nbapredictor,scaler = make_network('1317_boxscores_withspreads.csv',sklearn=True,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function I have is for turning the current nba team statistics (either over the entire season or some stretch) into an array of the same shape and information as the one used for the box scores above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction_data(filename):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    data = read_csv(filename)\n",
    "    #convert to per game stats and sort columns. \n",
    "    data['ORB'] =  np.divide(data['ORB'].values,data['G'].values)\n",
    "    data['DRB'] =  np.divide(data['DRB'].values,data['G'].values)\n",
    "    data['TRB'] =  np.divide(data['TRB'].values,data['G'].values)\n",
    "    data['AST'] =  np.divide(data['AST'].values,data['G'].values)\n",
    "    data['STL'] =  np.divide(data['STL'].values,data['G'].values)\n",
    "    data['BLK'] =  np.divide(data['BLK'].values,data['G'].values)\n",
    "    data['TOV'] =  np.divide(data['TOV'].values,data['G'].values)\n",
    "    data['PF'] =  np.divide(data['PF'].values,data['G'].values)\n",
    "    teams  = data['Team']\n",
    "\n",
    "    data = data[['ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK' ,'3P%','FG%' ,'FT%']]\n",
    "   # print(\"Here is every teams index value: \")\n",
    "   # print(teams)\n",
    "    return teams,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_maker(roadteam,hometeam,scaler):\n",
    "    \"\"\"After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    game = [game]\n",
    "    game = scaler.transform(game)\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filetouse = '1718nbateamstats.csv'  #downloaded from basketball reference, and specified date \n",
    "\n",
    "teams, stats =make_prediction_data(filetouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playoff teams + Index #\n",
    "----------------------\n",
    "Warriors 0\n",
    "-----------\n",
    "Rockets 1\n",
    "-----------\n",
    "Pelicans 2\n",
    "-----------\n",
    "Raptors 3 \n",
    "-----------\n",
    "Cavs 4\n",
    "-----------\n",
    "76ers 6\n",
    "-----------\n",
    "Timberwolves 7\n",
    "-----------\n",
    "Thunder 11\n",
    "-----------\n",
    "Wizards 12\n",
    "-----------\n",
    "Bucks 14\n",
    "-----------\n",
    "Trail Blazers 15\n",
    "-----------\n",
    "Pacers 16\n",
    "-----------\n",
    "Jazz 18\n",
    "-----------\n",
    "Celtics 19\n",
    "-----------\n",
    "Heat 22\n",
    "-----------\n",
    "Spurs 26\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now or tomorrow it would be smark to analyze all the different games, a ton have already been played, could be worth investigating what my playoff record is after round 1 for a specific series\n",
    "\n",
    "\n",
    "--Some things worth noting are playoff injuries, etc. like how the sixers are never really at their full strength and same goes for warriors but whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns the keras model for prediction, along with the scaling tool to normalize future data\n",
    "#conference finals HO LI FUK\n",
    "\n",
    "gswhou = game_maker(stats.values[0],stats.values[1],scaler)\n",
    "hougsw = game_maker(stats.values[1],stats.values[0],scaler)\n",
    "\n",
    "#\n",
    "\n",
    "clebos = game_maker(stats.values[4],stats.values[19],scaler)\n",
    "boscle = game_maker(stats.values[19],stats.values[4],scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.78057887])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbapredictor.predict(memgsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicted philly to cover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memgsw = game_maker(stats.values[29],stats.values[0],scaler)  #might not be grizz but def a bad team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#west round 2\n",
    "utahou = game_maker(stats.values[18],stats.values[1],scaler) #minny at houston\n",
    "houuta = game_maker(stats.values[1],stats.values[18],scaler) #vice versa\n",
    "nopgsw = game_maker(stats.values[2],stats.values[0],scaler)  # pelicans at gsw\n",
    "gswnop = game_maker(stats.values[0],stats.values[2],scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictor.predict(gswnop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#western conference round 1\n",
    "sasgsw = game_maker(stats.values[26],stats.values[0],scaler)\n",
    "gswsas = game_maker(stats.values[0],stats.values[26],scaler)\n",
    "minhou = game_maker(stats.values[7],stats.values[1],scaler)\n",
    "houmin = game_maker(stats.values[1],stats.values[7],scaler)\n",
    "utaokc = game_maker(stats.values[18],stats.values[11],scaler)\n",
    "okcuta = game_maker(stats.values[11],stats.values[18],scaler)\n",
    "noppor = game_maker(stats.values[2],stats.values[15],scaler)\n",
    "pornop = game_maker(stats.values[15],stats.values[2],scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictor.predict(indcle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#okc uta too close in this version, gonna re run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eastern conference round 1\n",
    "miaphi = game_maker(stats.values[22],stats.values[6],scaler)\n",
    "phimia = game_maker(stats.values[6],stats.values[22],scaler)\n",
    "milbos = game_maker(stats.values[14],stats.values[19],scaler)\n",
    "bosmil = game_maker(stats.values[19],stats.values[14],scaler)\n",
    "wastor = game_maker(stats.values[12],stats.values[3],scaler)\n",
    "torwas = game_maker(stats.values[3],stats.values[12],scaler)\n",
    "\n",
    "indcle = game_maker(stats.values[16],stats.values[4],scaler)\n",
    "cleind = game_maker(stats.values[4],stats.values[16],scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0761788])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbapredictor.predict(cleind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Round2matchups\n",
    "phibos = game_maker(stats.values[6],stats.values[19],scaler) #philly at boston\n",
    "bosphi = game_maker(stats.values[19],stats.values[6],scaler) #vice versa\n",
    "cletor = game_maker(stats.values[4],stats.values[3],scaler)  #cleveland at toronto\n",
    "torcle = game_maker(stats.values[3],stats.values[4],scaler) #vice versa\n",
    "utahou = game_maker(stats.values[18],stats.values[1],scaler) #minny at houston\n",
    "houuta = game_maker(stats.values[1],stats.values[18],scaler) #vice versa\n",
    "nopgsw = game_maker(stats.values[2],stats.values[0],scaler)  # pelicans at gsw\n",
    "gswnop = game_maker(stats.values[0],stats.values[2],scaler)\n",
    "\n",
    "gswsac = game_maker(stats.values[29],stats.values[0],scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#so who covers the various game 1s? \n",
    "nbapredictor.predict(cletor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictor.predict(nopgsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.8464921 + 0.45634875 + 0.10764076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.9274949 + 0.3562849 + 0.10068643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minhou = game_maker(stats.values[7],stats.values[1]) #minny at houston\n",
    "houmin = game_maker(stats.values[1],stats.values[7]) #vice versa\n",
    "\n",
    "game1 = game_maker(stats.values[1],stats.values[18])\n",
    "game2 = game_maker(stats.values[3],stats.values[15])\n",
    "game3 = game_maker(stats.values[7],stats.values[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbapredictor.predict(np.array([game1,game2,game3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
