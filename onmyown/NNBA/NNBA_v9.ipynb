{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Going to predict the spreads for games starting on march 17th\n",
    "\n",
    "\n",
    "Going to preprocess data so its better!\n",
    "\n",
    "\n",
    "Here's how you preprocess this:\n",
    "\n",
    "make an array of ALL X's including training, testing, and prediction. Just preprocess this.\n",
    "\n",
    "\n",
    "This means using the make neural net code, and including the prediction data including games in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import sys\n",
    "#import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#stderr = sys.stderr\n",
    "#sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This goes first \n",
    "def make_prediction_data(filename):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    data = read_csv(filename)\n",
    "    #convert to per game stats and sort columns. \n",
    "    data['ORB'] =  np.divide(data['ORB'].values,data['G'].values)\n",
    "    data['DRB'] =  np.divide(data['DRB'].values,data['G'].values)\n",
    "    data['TRB'] =  np.divide(data['TRB'].values,data['G'].values)\n",
    "    data['AST'] =  np.divide(data['AST'].values,data['G'].values)\n",
    "    data['STL'] =  np.divide(data['STL'].values,data['G'].values)\n",
    "    data['BLK'] =  np.divide(data['BLK'].values,data['G'].values)\n",
    "    data['TOV'] =  np.divide(data['TOV'].values,data['G'].values)\n",
    "    data['PF'] =  np.divide(data['PF'].values,data['G'].values)\n",
    "    teams  = data['Team']\n",
    "\n",
    "    data = data[['ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK' ,'3P%','FG%' ,'FT%']]\n",
    "    print(\"Here is every teams index value: \")\n",
    "    print(teams)\n",
    "    return teams,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_maker(roadteam,hometeam):\n",
    "    \"\"\"After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    game.reshape(1,- 1)\n",
    "    game = scale.transform(game)\n",
    "\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here's where you create an array of all the games\n",
    "games = game_maker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(FILENAME,games):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \"\"\"Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and proper hot encoding is done. Other stuff too probably.\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    X_train : array\n",
    "        Numpy array of the training inputs.\n",
    "    y_train : array\n",
    "        Numpy array of the training outputs.\n",
    "    \n",
    "    X_test : array\n",
    "        Numpy array of the testing inputs.\n",
    "    y_test : array\n",
    "        Numpy array of the testing outputs.\n",
    "    Sike!\n",
    "    \n",
    "    model : object\n",
    "        MLP which can predict the outcome of NBA games\n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    data = read_csv(FILENAME)\n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values)\n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "    del data['VENUE_Home'],data['VENUE_Road']\n",
    "    #print(data)\n",
    "    \n",
    "    \n",
    "\n",
    "    dat = []\n",
    "\n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "    \n",
    "\n",
    "    \"\"\"At this point in the data dat is an array arranged as \n",
    "        OR  DR  TOT   A  PF  ST  TO  BL  PTS       3P%       FG%       FT% x2  (for road then home )\n",
    "    so next up is to hot pull road and home points \n",
    "    \n",
    "    road points is column 8 and home points is column 20. \n",
    "    \n",
    "    So grab those from dat and make y. \n",
    "    \n",
    "    X is every other column, so merge everyone else \n",
    "    \n",
    "    \"\"\"\n",
    "    dat = np.array(dat)   \n",
    "    roadpts = dat[:,8]\n",
    "\n",
    "    homepts = dat[:,21]\n",
    "    endspreadS = roadpts-homepts\n",
    "    openingspreadS = dat[:,9]\n",
    "#    print(\"opening spread:\" + str(dat[:,9]))\n",
    "    y = []\n",
    "    for j in range(len(endspreadS)):\n",
    "        openspread = openingspreadS[j]\n",
    "       # print(\"this is the spread of the road team \" + str(openspread))\n",
    "        endspread = endspreadS[j]\n",
    "       # print(\"the road team won by  .. \" + str(endspread))\n",
    "       # if endspread>openspread:\n",
    "        #    y.append(np.array([0,1,0]))  #OK, now make sure this is formateed properly!\n",
    "        if openspread + endspread < 0:\n",
    "            y.append(np.array([0,1,0]))\n",
    "        elif openspread + endspread > 0:\n",
    "            y.append(np.array([1,0,0]))\n",
    "        else: \n",
    "            y.append(np.array([0,0,1]))\n",
    "\n",
    "\n",
    "\n",
    "    y = np.array(y)\n",
    "    X1 = np.concatenate((dat[:,0:8],dat[:,10:21]),axis=1)\n",
    "    X = np.concatenate((X1,dat[:,23:26]),axis=1)    #need to go one further column to snag HFT% \n",
    "    #print(X[0])\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "   \n",
    "    X = scaler.transform(X)\n",
    "    #print(X[0])\n",
    "    \n",
    "\n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.27)\n",
    "    #print((X[0]))\n",
    "    #print(np.shape(X[0]))\n",
    "\n",
    "    model = MLPClassifier()\n",
    "    model.shuffle = True\n",
    "    model.batch_size = 25\n",
    "    #model.n_layers_ = 1000000\n",
    "    #model.n_outputs_= 1000000\n",
    "    #These don't do anything, have to adjust the layers in some different way! Keras is useful for this.\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test,y_test))\n",
    "    return model,scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If spread of road team is + that means they are supposed to lose by that much\n",
    "if the end spread is - that means the road team lost by that much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction_data(filename):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    data = read_csv(filename)\n",
    "    #convert to per game stats and sort columns. \n",
    "    data['ORB'] =  np.divide(data['ORB'].values,data['G'].values)\n",
    "    data['DRB'] =  np.divide(data['DRB'].values,data['G'].values)\n",
    "    data['TRB'] =  np.divide(data['TRB'].values,data['G'].values)\n",
    "    data['AST'] =  np.divide(data['AST'].values,data['G'].values)\n",
    "    data['STL'] =  np.divide(data['STL'].values,data['G'].values)\n",
    "    data['BLK'] =  np.divide(data['BLK'].values,data['G'].values)\n",
    "    data['TOV'] =  np.divide(data['TOV'].values,data['G'].values)\n",
    "    data['PF'] =  np.divide(data['PF'].values,data['G'].values)\n",
    "    teams  = data['Team']\n",
    "\n",
    "    data = data[['ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK' ,'3P%','FG%' ,'FT%']]\n",
    "    print(\"Here is every teams index value: \")\n",
    "    print(teams)\n",
    "    return teams,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_maker(roadteam,hometeam):\n",
    "    \"\"\"After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    game.reshape(1,- 1)\n",
    "    game = scale.transform(game)\n",
    "\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is every teams index value: \n",
      "0     Golden State Warriors*\n",
      "1     Houston Rockets*      \n",
      "2     Toronto Raptors*      \n",
      "3     New Orleans Pelicans  \n",
      "4     Minnesota Timberwolves\n",
      "5     Oklahoma City Thunder \n",
      "6     Denver Nuggets        \n",
      "7     Cleveland Cavaliers   \n",
      "8     Los Angeles Clippers  \n",
      "9     Washington Wizards    \n",
      "10    Charlotte Hornets     \n",
      "11    Los Angeles Lakers    \n",
      "12    Brooklyn Nets         \n",
      "13    Portland Trail Blazers\n",
      "14    Phoenix Suns          \n",
      "15    Indiana Pacers        \n",
      "16    Philadelphia 76ers    \n",
      "17    Orlando Magic         \n",
      "18    Boston Celtics*       \n",
      "19    New York Knicks       \n",
      "20    Atlanta Hawks         \n",
      "21    Milwaukee Bucks       \n",
      "22    Utah Jazz             \n",
      "23    Dallas Mavericks      \n",
      "24    Miami Heat            \n",
      "25    San Antonio Spurs     \n",
      "26    Chicago Bulls         \n",
      "27    Detroit Pistons       \n",
      "28    Sacramento Kings      \n",
      "29    Memphis Grizzlies     \n",
      "30    League Average        \n",
      "Name: Team, dtype: object\n"
     ]
    }
   ],
   "source": [
    "teams, stats =make_prediction_data('teamstats_319.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 9.22857143 34.17142857 43.4        21.75714286 19.8         8.62857143\n 13.9         4.72857143  0.365       0.463       0.788       9.25714286\n 35.21428571 44.47142857 22.44285714 20.1         7.17142857 13.87142857\n  4.65714286  0.374       0.45        0.766     ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1302f732efeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgame1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgame2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgame3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgame4\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgame_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgame5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-cd51138ae097>\u001b[0m in \u001b[0;36mgame_maker\u001b[0;34m(roadteam, hometeam)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroadteam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhometeam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy, warn_on_dtype=True,\n\u001b[0;32m--> 681\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 9.22857143 34.17142857 43.4        21.75714286 19.8         8.62857143\n 13.9         4.72857143  0.365       0.463       0.788       9.25714286\n 35.21428571 44.47142857 22.44285714 20.1         7.17142857 13.87142857\n  4.65714286  0.374       0.45        0.766     ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "game1 = game_maker(stats.values[1],stats.values[18])\n",
    "game2 = game_maker(stats.values[3],stats.values[15])\n",
    "game3 = game_maker(stats.values[7],stats.values[17])\n",
    "game4 =  game_maker(stats.values[11],stats.values[2])\n",
    "game5 = game_maker(stats.values[24],stats.values[4])\n",
    "game6 = game_maker(stats.values[20],stats.values[22])\n",
    "game7 = game_maker(stats.values[26],stats.values[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602256699576869\n"
     ]
    }
   ],
   "source": [
    "noahbets,scale = make_network('1517_boxscores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noahbets.predict(np.array([game1,game2,game3,game4,game5,game6,game7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ATS Record 3//17:\n",
    "*Mavs* vs. Nets X\n",
    "\n",
    "Pistons vs. *Blazers*\n",
    "\n",
    "Hawks vs. *Bucks* X\n",
    "\n",
    "Pacers vs. *Wizards* Y\n",
    "\n",
    "Rockets vs. *Pelicans* Y\n",
    "\n",
    "*Hornets* vs. Knicks X\n",
    "\n",
    "Cavs vs. *Bulls* Y\n",
    "\n",
    "*Nuggets* vs. Grizzlies X\n",
    "\n",
    "Twolves vs. *Spurs* \n",
    "\n",
    "Kings vs. *Jazz*\n",
    "\n",
    "*Dubs* vs. Suns ***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winners 3/10:\n",
    "10 Hornets Y\n",
    "24 Heat Y\n",
    "27 Spurs N\n",
    "26 Mavs Y\n",
    "12 Clippers Y\n",
    "\n",
    "Winners 3/11:\n",
    "4 Raptors Y\n",
    "25 Bulls Y\n",
    "0 GSW N\n",
    "3 Pelicans N\n",
    "5 Nuggets Y\n",
    "26 Rockets Y\n",
    "13 Nets N\n",
    "7 Cavs N\n",
    "18 Celtics N\n",
    "\n",
    "Winners 3/12:\n",
    "Blazers Y\n",
    "Spurs N\n",
    "Bucks Y\n",
    "Thunder Y\n",
    "\n",
    "\n",
    "Winners 3/13:\n",
    "\n",
    "Philly N\n",
    "Wash N\n",
    "OKC Y\n",
    "Toronto Y\n",
    "Dallas Y\n",
    "Bulls N\n",
    "Pels Y\n",
    "Spurs Y\n",
    "UTAH Y\n",
    "Cle Y\n",
    "Lakers Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game1 = game_maker(stats.values[24],stats.values[14])\n",
    "game2 = game_maker(stats.values[27],stats.values[18])\n",
    "game3 = game_maker(stats.values[21],stats.values[22])\n",
    "game4 =  game_maker(stats.values[16],stats.values[10])\n",
    "game5 = game_maker(stats.values[2],stats.values[3])\n",
    "game6 = game_maker(stats.values[11],stats.values[19])\n",
    "game7 = game_maker(stats.values[7],stats.values[26])\n",
    "game8 = game_maker(stats.values[6],stats.values[29])\n",
    "game9 = game_maker(stats.values[5],stats.values[25])\n",
    "game10 =game_maker(stats.values[28],stats.values[23])\n",
    "game11 =game_maker(stats.values[0],stats.values[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "20-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted winners on March 9th:\n",
    "\n",
    "Indiana\n",
    "Chicago \n",
    "toronto\n",
    "nop\n",
    "utah\n",
    "knicks    *\n",
    "lakers\n",
    "orlando  *\n",
    "warriors\n",
    "clippers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "20/29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrangement of Data:\n",
    "Away :      OR  DR  TOT   A  PF  ST  TO  BL  PTS   3P%       FG%       FT%\n",
    "  Home: OR  DR  TOT   A  PF  ST  TO  BL  3P%  FG%  FT%| AW HW\n",
    "      0    1   2   3   4   5  6    7   8    9   10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "1. Road Orbs\n",
    "2. Road Drbs\n",
    "3. Road Trbs\n",
    "4. Road Asts\n",
    "5. Road Pfs\n",
    "6. Road Stls\n",
    "7. Road Tos. \n",
    "8. Road Blks \n",
    "9. Road 3p%\n",
    "10. Road Fg%\n",
    "11. Road Ft% \n",
    "12. Road venue Home (0)  REMOVED\n",
    "13. Road venue Away (1) REMOVED\n",
    "14. Home Orbs\n",
    "15. Home Drbs\n",
    "16. Home Trbs\n",
    "17. Home Asts\n",
    "18. Home Pfs\n",
    "19. Home Stls\n",
    "20. Home Tos. \n",
    "21. Home Blks \n",
    "22. Home 3p%\n",
    "23. Home Fg%\n",
    "24. Home Ft% \n",
    "25. Home venue Home (0) REMOVED\n",
    "26. Home venue Away (1) REMOVED\n",
    "\n",
    "With Outputs \n",
    "\n",
    "27. Home team win (1)\n",
    "28. Road team win (0)\n",
    "\n",
    "\n",
    "So you enter the statistics of both teams, and it gives a classification of whether or not the home or away team wins.\n",
    "Unclear how good this actually is at characterizing teams. Should use team stats from as recent a metric as possible to reflect current gameplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a raw version where I pull the last 5 stats of wiz vs pels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/8 Games and if it was correct:\n",
    "\n",
    "Suns @ OKC YES\n",
    "\n",
    "Nets @ HOR NO\n",
    "\n",
    "Bos @ Min NO\n",
    "\n",
    "Phi @ Mia YES\n",
    "\n",
    "Sas @ GSW Says spurs, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start. What's left?\n",
    "\n",
    "1. What about assists, rebounds, steals, etc.? Can a table do that too? \n",
    "\n",
    "2. Hot encode wins and losses. Need to move that result column and delete everyhting except W and L.\n",
    "\n",
    "3. Normalize data?\n",
    "\n",
    "4. Create a net\n",
    "\n",
    "5. Figure out prediction data, go by season averages? L5 averages? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneccesary stats. Flatten 2 adjascent rows because they're the same game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([10,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
