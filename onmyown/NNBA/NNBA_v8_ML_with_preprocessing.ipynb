{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#pd.set_option('display.max_columns', None)  \n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(FILENAME):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \"\"\"Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and proper hot encoding is done. Other stuff too probably.\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    X_train : array\n",
    "        Numpy array of the training inputs.\n",
    "    y_train : array\n",
    "        Numpy array of the training outputs.\n",
    "    \n",
    "    X_test : array\n",
    "        Numpy array of the testing inputs.\n",
    "    y_test : array\n",
    "        Numpy array of the testing outputs.\n",
    "    Sike!\n",
    "    \n",
    "    model : object\n",
    "        MLP which can predict the outcome of NBA games\n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    data = read_csv(FILENAME)\n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values)\n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "    del data['VENUE_Home'],data['VENUE_Road']\n",
    "    #print(data)\n",
    "    \n",
    "    dat = []\n",
    "\n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "            \n",
    "    \"\"\"At this point in the data dat is an array arranged as \n",
    "        OR  DR  TOT   A  PF  ST  TO  BL  PTS       3P%       FG%       FT% x2  (for road then home )\n",
    "    so next up is to hot pull road and home points \n",
    "    \n",
    "    road points is column 8 and home points is column 20. \n",
    "    \n",
    "    So grab those from dat and make y. \n",
    "    \n",
    "    X is every other column, so merge everyone else \n",
    "    \n",
    "    \"\"\"\n",
    "    dat = np.array(dat)   \n",
    "  #  print(dat[0])\n",
    "    y = []\n",
    "    for j in range(len(dat)):\n",
    "        roadpts = dat[j,8]\n",
    "        homepts = dat[j,20]\n",
    "       # print(home,road)\n",
    "    #distinguish home win or road win. \n",
    "        if homepts > roadpts:\n",
    "            y.append(np.array([0,1]))  # 0 1 mean home won\n",
    "        else:\n",
    "            y.append(np.array([1,0]))  #  1 0 means away won. \n",
    "    y = np.array(y)\n",
    "    X1 = np.concatenate((dat[:,0:8],dat[:,9:20]),axis=1)\n",
    "    X = np.concatenate((X1,dat[:,21:24]),axis=1)    #need to go one further column to snag HFT% \n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.4)\n",
    "  #  print(X_train[0])\n",
    "  #  print(X_test[0])\n",
    "\n",
    "    model = MLPClassifier()\n",
    "    model.batch_size = 20\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    print(model.score(X_test,y_test))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8704761904761905\n"
     ]
    }
   ],
   "source": [
    "noahbets = make_network('1517_boxscores_nospreads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction_data(filename):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    data = read_csv(filename)\n",
    "    #convert to per game stats and sort columns. \n",
    "    data['ORB'] =  np.divide(data['ORB'].values,data['G'].values)\n",
    "    data['DRB'] =  np.divide(data['DRB'].values,data['G'].values)\n",
    "    data['TRB'] =  np.divide(data['TRB'].values,data['G'].values)\n",
    "    data['AST'] =  np.divide(data['AST'].values,data['G'].values)\n",
    "    data['STL'] =  np.divide(data['STL'].values,data['G'].values)\n",
    "    data['BLK'] =  np.divide(data['BLK'].values,data['G'].values)\n",
    "    data['TOV'] =  np.divide(data['TOV'].values,data['G'].values)\n",
    "    data['PF'] =  np.divide(data['PF'].values,data['G'].values)\n",
    "    teams  = data['Team']\n",
    "\n",
    "    data = data[['ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK' ,'3P%','FG%' ,'FT%']]\n",
    "    print(\"Here is every teams index value: \")\n",
    "    print(teams)\n",
    "    return teams,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_maker(roadteam,hometeam):\n",
    "    \"\"\"After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game =np.concatenate((roadteam,hometeam))\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is every teams index value: \n",
      "0      Golden State Warriors\n",
      "1            Houston Rockets\n",
      "2     Minnesota Timberwolves\n",
      "3           Toronto Raptors*\n",
      "4       New Orleans Pelicans\n",
      "5             Denver Nuggets\n",
      "6        Cleveland Cavaliers\n",
      "7      Oklahoma City Thunder\n",
      "8         Washington Wizards\n",
      "9         Los Angeles Lakers\n",
      "10         Charlotte Hornets\n",
      "11      Los Angeles Clippers\n",
      "12              Phoenix Suns\n",
      "13            Indiana Pacers\n",
      "14             Brooklyn Nets\n",
      "15             Orlando Magic\n",
      "16        Philadelphia 76ers\n",
      "17            Boston Celtics\n",
      "18    Portland Trail Blazers\n",
      "19           New York Knicks\n",
      "20             Atlanta Hawks\n",
      "21           Milwaukee Bucks\n",
      "22                 Utah Jazz\n",
      "23                Miami Heat\n",
      "24          Dallas Mavericks\n",
      "25             Chicago Bulls\n",
      "26           Detroit Pistons\n",
      "27         San Antonio Spurs\n",
      "28          Sacramento Kings\n",
      "29         Memphis Grizzlies\n",
      "30            League Average\n",
      "Name: Team, dtype: object\n"
     ]
    }
   ],
   "source": [
    "teams, stats =make_prediction_data('3-12teamstats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok let's do ML tonight :DK\n",
    "\n",
    "Games: \n",
    "Rockets @ Blazers\n",
    "Raptors @ Magic\n",
    "Thunder @ Celtics\n",
    "Clippers @ Twolves \n",
    "Mavs @ Pels\n",
    "Hawks @ Jazz\n",
    "Pistons @ Suns\n",
    "\n",
    "\n",
    "How'd it do yesterday? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "game1 = game_maker(stats.values[1],stats.values[18])\n",
    "game2 = game_maker(stats.values[3],stats.values[15])\n",
    "game3 = game_maker(stats.values[7],stats.values[17])\n",
    "game4 =  game_maker(stats.values[11],stats.values[2])\n",
    "game5 = game_maker(stats.values[24],stats.values[4])\n",
    "game6 = game_maker(stats.values[20],stats.values[22])\n",
    "game7 = game_maker(stats.values[26],stats.values[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noahbets.predict(np.array([game1,game2,game3,game4,game5,game6,game7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
