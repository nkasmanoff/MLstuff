{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Going to predict the spreads for games starting on march 17th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import sys\n",
    "#import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#stderr = sys.stderr\n",
    "#sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(FILENAME):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \"\"\"Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and proper hot encoding is done. Other stuff too probably.\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    X_train : array\n",
    "        Numpy array of the training inputs.\n",
    "    y_train : array\n",
    "        Numpy array of the training outputs.\n",
    "    \n",
    "    X_test : array\n",
    "        Numpy array of the testing inputs.\n",
    "    y_test : array\n",
    "        Numpy array of the testing outputs.\n",
    "    Sike!\n",
    "    \n",
    "    model : object\n",
    "        MLP which can predict the outcome of NBA games\n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    data = read_csv(FILENAME)\n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values)\n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "    del data['VENUE_Home'],data['VENUE_Road']\n",
    "    #print(data)\n",
    "    \n",
    "    print(data)\n",
    "\n",
    "    dat = []\n",
    "\n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "    \n",
    "\n",
    "    \"\"\"At this point in the data dat is an array arranged as \n",
    "        OR  DR  TOT   A  PF  ST  TO  BL  PTS       3P%       FG%       FT% x2  (for road then home )\n",
    "    so next up is to hot pull road and home points \n",
    "    \n",
    "    road points is column 8 and home points is column 20. \n",
    "    \n",
    "    So grab those from dat and make y. \n",
    "    \n",
    "    X is every other column, so merge everyone else \n",
    "    \n",
    "    \"\"\"\n",
    "    dat = np.array(dat)   \n",
    "    roadpts = dat[:,8]\n",
    "\n",
    "    homepts = dat[:,21]\n",
    "    endspreadS = roadpts-homepts\n",
    "    openingspreadS = dat[:,9]\n",
    "#    print(\"opening spread:\" + str(dat[:,9]))\n",
    "    y = []\n",
    "    for j in range(len(endspreadS)):\n",
    "        openspread = openingspreadS[j]\n",
    "       # print(\"this is the spread of the road team \" + str(openspread))\n",
    "        endspread = endspreadS[j]\n",
    "       # print(\"the road team won by  .. \" + str(endspread))\n",
    "       # if endspread>openspread:\n",
    "        #    y.append(np.array([0,1,0]))  #OK, now make sure this is formateed properly!\n",
    "        if openspread + endspread <0:\n",
    "            y.append(np.array([0,1,0]))\n",
    "        elif openspread + endspread >0:\n",
    "            y.append(np.array([1,0,0]))\n",
    "        else: \n",
    "            y.append(np.array([0,0,1]))\n",
    "\n",
    "\n",
    "\n",
    "    y = np.array(y)\n",
    "    X1 = np.concatenate((dat[:,0:8],dat[:,10:21]),axis=1)\n",
    "    X = np.concatenate((X1,dat[:,23:26]),axis=1)    #need to go one further column to snag HFT% \n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.27)\n",
    "    #print((X[0]))\n",
    "    #print(np.shape(X[0]))\n",
    "\n",
    "    model = MLPClassifier()\n",
    "    model.shuffle = True\n",
    "    model.batch_size = 25\n",
    "    #model.n_layers_ = 1000000\n",
    "    #model.n_outputs_= 1000000\n",
    "    #These don't do anything, have to adjust the layers in some different way! Keras is useful for this.\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test,y_test))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If spread of road team is + that means they are supposed to lose by that much\n",
    "if the end spread is - that means the road team lost by that much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction_data(filename):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    data = read_csv(filename)\n",
    "    #convert to per game stats and sort columns. \n",
    "    data['ORB'] =  np.divide(data['ORB'].values,data['G'].values)\n",
    "    data['DRB'] =  np.divide(data['DRB'].values,data['G'].values)\n",
    "    data['TRB'] =  np.divide(data['TRB'].values,data['G'].values)\n",
    "    data['AST'] =  np.divide(data['AST'].values,data['G'].values)\n",
    "    data['STL'] =  np.divide(data['STL'].values,data['G'].values)\n",
    "    data['BLK'] =  np.divide(data['BLK'].values,data['G'].values)\n",
    "    data['TOV'] =  np.divide(data['TOV'].values,data['G'].values)\n",
    "    data['PF'] =  np.divide(data['PF'].values,data['G'].values)\n",
    "    teams  = data['Team']\n",
    "\n",
    "    data = data[['ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK' ,'3P%','FG%' ,'FT%']]\n",
    "    print(\"Here is every teams index value: \")\n",
    "    print(teams)\n",
    "    return teams,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_maker(roadteam,hometeam):\n",
    "    \"\"\"After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is every teams index value: \n",
      "0     Golden State Warriors*\n",
      "1     Toronto Raptors*      \n",
      "2     Houston Rockets*      \n",
      "3     New Orleans Pelicans  \n",
      "4     Minnesota Timberwolves\n",
      "5     Denver Nuggets        \n",
      "6     Cleveland Cavaliers   \n",
      "7     Oklahoma City Thunder \n",
      "8     Los Angeles Clippers  \n",
      "9     Charlotte Hornets     \n",
      "10    Brooklyn Nets         \n",
      "11    Washington Wizards    \n",
      "12    Indiana Pacers        \n",
      "13    Los Angeles Lakers    \n",
      "14    Philadelphia 76ers    \n",
      "15    Portland Trail Blazers\n",
      "16    Milwaukee Bucks       \n",
      "17    New York Knicks       \n",
      "18    Phoenix Suns          \n",
      "19    Miami Heat            \n",
      "20    Orlando Magic         \n",
      "21    Boston Celtics*       \n",
      "22    Atlanta Hawks         \n",
      "23    San Antonio Spurs     \n",
      "24    Chicago Bulls         \n",
      "25    Utah Jazz             \n",
      "26    Detroit Pistons       \n",
      "27    Dallas Mavericks      \n",
      "28    Sacramento Kings      \n",
      "29    Memphis Grizzlies     \n",
      "30    League Average        \n",
      "Name: Team, dtype: object\n"
     ]
    }
   ],
   "source": [
    "teams, stats =make_prediction_data('teamstats_322.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      OR  DR  TOT   A  PF  ST  TO  BL  PTS  SPREAD       3P%       FG%  \\\n",
      "0     13  29  42   17  22  6   18  6   88   9.5     0.333333  0.367816   \n",
      "1     11  40  51   31  22  12  14  5   117 -9.5     0.371429  0.478723   \n",
      "2     6   25  31   19  19  9   11  5   104  6.0     0.333333  0.487805   \n",
      "3     5   29  34   22  18  5   12  3   113 -6.0     0.684211  0.520000   \n",
      "4     21  34  55   25  19  13  13  3   129  8.0     0.500000  0.479592   \n",
      "5     8   27  35   24  19  11  16  6   100 -8.0     0.212121  0.470588   \n",
      "6     16  36  52   27  22  5   10  7   108  4.0     0.250000  0.484536   \n",
      "7     15  30  45   20  15  5   11  4   96  -4.0     0.333333  0.382022   \n",
      "8     10  39  49   26  27  8   15  8   121  5.0     0.375000  0.432692   \n",
      "9     8   44  52   30  23  11  16  6   130 -5.0     0.526316  0.505376   \n",
      "10    15  29  44   22  19  8   16  3   117  14.0    0.340909  0.443299   \n",
      "11    12  35  47   36  20  13  19  9   122 -14.0    0.343750  0.539326   \n",
      "12    8   32  40   17  24  8   13  0   91   7.0     0.181818  0.416667   \n",
      "13    14  37  51   17  22  8   11  0   109 -7.0     0.166667  0.476744   \n",
      "14    11  40  51   27  22  5   10  10  107  0.0     0.304348  0.449438   \n",
      "15    10  36  46   23  22  4   8   5   96   0.0     0.187500  0.423913   \n",
      "16    15  30  45   20  23  6   10  5   98   3.5     0.333333  0.418605   \n",
      "17    11  34  45   19  25  6   13  11  102 -3.5     0.458333  0.450000   \n",
      "18    11  47  58   18  22  7   24  4   107  4.0     0.333333  0.445783   \n",
      "19    5   28  33   31  29  16  11  5   102 -4.0     0.157895  0.413043   \n",
      "20    13  40  53   19  23  7   10  3   103 -7.0     0.272727  0.414894   \n",
      "21    5   38  43   21  22  5   13  10  97   7.0     0.291667  0.428571   \n",
      "22    10  31  41   24  20  5   13  5   113  3.0     0.285714  0.511628   \n",
      "23    10  31  41   20  29  6   18  3   94  -3.0     0.250000  0.467532   \n",
      "24    10  29  39   29  23  10  14  1   114 -5.0     0.241379  0.511628   \n",
      "25    11  28  39   21  24  10  15  4   120  5.0     0.342857  0.505618   \n",
      "26    12  28  40   25  20  14  19  4   99   2.5     0.300000  0.425532   \n",
      "27    14  38  52   28  19  13  21  7   114 -2.5     0.461538  0.500000   \n",
      "28    3   33  36   22  25  6   11  6   99  -1.0     0.347826  0.500000   \n",
      "29    18  37  55   25  21  5   12  1   105  1.0     0.440000  0.391304   \n",
      "...   ..  ..  ..   ..  .. ..   .. ..   ...  ...          ...       ...   \n",
      "5220  10  28  38   19  21  9   13  1   105 -2.5     0.312500  0.413043   \n",
      "5221  11  41  52   21  23  6   12  8   133  2.5     0.320000  0.500000   \n",
      "5222  10  28  38   23  17  5   10  2   99  -6.0     0.317073  0.469880   \n",
      "5223  9   26  35   17  16  8   8   3   105  6.0     0.318182  0.538462   \n",
      "5224  8   32  40   15  26  11  21  4   94  -1.0     0.300000  0.412500   \n",
      "5225  16  40  56   23  22  16  17  8   118  1.0     0.346154  0.433333   \n",
      "5226  5   22  27   19  25  9   18  3   78   10.0    0.176471  0.391304   \n",
      "5227  10  38  48   23  26  11  16  6   116 -10.0    0.476190  0.571429   \n",
      "5228  13  32  45   23  26  8   17  2   111  7.0     0.433333  0.428571   \n",
      "5229  11  34  45   25  18  13  15  7   120 -7.0     0.375000  0.470588   \n",
      "5230  4   34  38   22  18  6   10  6   113 -6.5     0.548387  0.540541   \n",
      "5231  7   26  33   10  19  6   12  2   87   6.5     0.320000  0.417722   \n",
      "5232  13  31  44   23  25  11  14  4   108  2.0     0.466667  0.409091   \n",
      "5233  16  33  49   16  22  9   15  10  101 -2.0     0.130435  0.422222   \n",
      "5234  14  33  47   20  11  3   7   5   88   7.0     0.259259  0.382022   \n",
      "5235  10  36  46   20  16  4   11  4   96  -7.0     0.459459  0.435294   \n",
      "5236  15  32  47   17  17  7   15  4   89   5.5     0.333333  0.380952   \n",
      "5237  9   32  41   29  16  9   9   4   104 -5.5     0.333333  0.494253   \n",
      "5238  9   25  34   15  19  15  17  3   77   6.5     0.217391  0.354430   \n",
      "5239  12  34  46   26  20  7   20  9   110 -6.5     0.454545  0.543210   \n",
      "5240  8   24  32   21  23  5   18  4   90   1.0     0.272727  0.421053   \n",
      "5241  17  35  52   23  25  8   13  3   120 -1.0     0.480000  0.527473   \n",
      "5242  14  29  43   23  22  7   8   6   108  2.0     0.472222  0.407407   \n",
      "5243  16  24  40   15  24  5   11  6   97  -2.0     0.240000  0.469136   \n",
      "5244  8   33  41   15  22  11  16  9   112  7.5     0.416667  0.530120   \n",
      "5245  13  30  43   18  21  6   17  9   97  -7.5     0.325581  0.363636   \n",
      "5246  9   26  35   19  25  5   14  3   101  2.5     0.384615  0.402439   \n",
      "5247  8   37  45   24  25  12  10  7   115 -2.5     0.370370  0.519481   \n",
      "5248  9   39  48   17  15  7   11  6   93   5.0     0.240000  0.402439   \n",
      "5249  7   32  39   22  23  7   10  5   89  -5.0     0.365854  0.385542   \n",
      "\n",
      "           FT%  \n",
      "0     0.750000  \n",
      "1     0.736842  \n",
      "2     1.000000  \n",
      "3     1.000000  \n",
      "4     0.884615  \n",
      "5     0.722222  \n",
      "6     0.625000  \n",
      "7     0.785714  \n",
      "8     0.722222  \n",
      "9     0.764706  \n",
      "10    0.800000  \n",
      "11    0.833333  \n",
      "12    0.772727  \n",
      "13    0.827586  \n",
      "14    0.833333  \n",
      "15    0.750000  \n",
      "16    0.689655  \n",
      "17    0.703704  \n",
      "18    0.757576  \n",
      "19    0.884615  \n",
      "20    0.730769  \n",
      "21    0.720000  \n",
      "22    0.730769  \n",
      "23    0.666667  \n",
      "24    0.703704  \n",
      "25    0.818182  \n",
      "26    0.722222  \n",
      "27    0.777778  \n",
      "28    0.625000  \n",
      "29    0.733333  \n",
      "...        ...  \n",
      "5220  0.760000  \n",
      "5221  0.891892  \n",
      "5222  0.888889  \n",
      "5223  0.736842  \n",
      "5224  0.655172  \n",
      "5225  0.775000  \n",
      "5226  0.600000  \n",
      "5227  0.750000  \n",
      "5228  0.833333  \n",
      "5229  0.911765  \n",
      "5230  0.761905  \n",
      "5231  0.764706  \n",
      "5232  0.625000  \n",
      "5233  0.687500  \n",
      "5234  0.764706  \n",
      "5235  0.625000  \n",
      "5236  0.900000  \n",
      "5237  0.900000  \n",
      "5238  0.666667  \n",
      "5239  0.700000  \n",
      "5240  0.653846  \n",
      "5241  0.705882  \n",
      "5242  0.806452  \n",
      "5243  0.576923  \n",
      "5244  0.608696  \n",
      "5245  0.730769  \n",
      "5246  0.689655  \n",
      "5247  0.781250  \n",
      "5248  0.840000  \n",
      "5249  0.769231  \n",
      "\n",
      "[5250 rows x 13 columns]\n",
      "0.7136812411847673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noahbets = make_network('1517_boxscores_withspreads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noahbets.predict(np.array([game1,game2,game3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On March 26th, using team stats as of 3/21\n",
    "\n",
    "Hornets\n",
    "Lakers\n",
    "sixers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ATS Predictions 3/21:\n",
    "--------------------\n",
    "Hornets Cha\n",
    "\n",
    "Raptors Raps\n",
    "\n",
    "76ers Sixers\n",
    "\n",
    "x Knicks Heat\n",
    "\n",
    "Bulls Bulls Bulls\n",
    "\n",
    "Clips Clips Clips\n",
    "\n",
    "Pels Pels Pels\n",
    "\n",
    "x Wiz Spurs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "10 +10 +10 + 10  -11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7+2+2 +3 +6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4+2+6+3+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
