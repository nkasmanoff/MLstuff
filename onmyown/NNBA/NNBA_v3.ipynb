{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#pd.set_option('display.max_columns', None)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makedata(FILENAME):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    \"\"\"Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and proper hot encoding is done. Other stuff too probably.\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    X_train : array\n",
    "        Numpy array of the training inputs.\n",
    "    y_train : array\n",
    "        Numpy array of the training outputs.\n",
    "    \n",
    "    X_test : array\n",
    "        Numpy array of the testing inputs.\n",
    "    y_test : array\n",
    "        Numpy array of the testing outputs.\n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    data = read_csv(FILENAME)\n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values)\n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "    del data['VENUE_Home'],data['VENUE_Road']\n",
    "    print(data)\n",
    "\n",
    "    #reshape the data so it will fit together. \n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    \n",
    "    #this puts each full game box score on the same line. Originally it had\n",
    "    #every 2 rows represent the home and road team, gotta put it on one. \n",
    "    #Unclear if this gives any information to the neural net, maybe it does if its just one 1 or 0 not 2.\n",
    "    \n",
    "    #the way to make it just one is to \"forget\" 2 columns, will name those 2 in a sec. \n",
    "    dat = []\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "    dat = np.array(dat)    \n",
    "    \n",
    "   # if show:\n",
    "      #  print(data)\n",
    "    #separate X and y, while hot encoding the winner and loser too. \n",
    "    y = []\n",
    "    for j in range(len(dat)):\n",
    "        home = dat[j,8]\n",
    "        road = dat[j,20]\n",
    "       # print(home,road)\n",
    "    #distinguish home win or road win. \n",
    "        if home > road:\n",
    "            y.append(np.array([0,1]))  # 0 1 mean home won\n",
    "        else:\n",
    "            y.append(np.array([1,0]))  #  1 0 means away won. \n",
    "    y = np.array(y)  #must be an array!\n",
    "    #now split up that big guy to get X\n",
    "    X1 = np.concatenate((dat[:,0:10],dat[:,11:21]),axis=1)\n",
    "    X = np.concatenate((X1,dat[:,22:28]),axis=1)   \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = makedata('1617_boxscores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0     0.367816  0.333333  13  29   42  17  22   6  18   6   88  0.750000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "1. Road Orbs\n",
    "2. Road Drbs\n",
    "3. Road Trbs\n",
    "4. Road Asts\n",
    "5. Road Pfs\n",
    "6. Road Stls\n",
    "7. Road Tos. \n",
    "8. Road Blks \n",
    "9. Road 3p%\n",
    "10. Road Fg%\n",
    "11. Road Ft% \n",
    "12. Road venue Home (0)  REMOVED\n",
    "13. Road venue Away (1) REMOVED\n",
    "14. Home Orbs\n",
    "15. Home Drbs\n",
    "16. Home Trbs\n",
    "17. Home Asts\n",
    "18. Home Pfs\n",
    "19. Home Stls\n",
    "20. Home Tos. \n",
    "21. Home Blks \n",
    "22. Home 3p%\n",
    "23. Home Fg%\n",
    "24. Home Ft% \n",
    "25. Home venue Home (0) REMOVED\n",
    "26. Home venue Away (1) REMOVED\n",
    "\n",
    "With Outputs \n",
    "\n",
    "27. Home team win (1)\n",
    "28. Road team win (0)\n",
    "\n",
    "\n",
    "So you enter the statistics of both teams, and it gives a classification of whether or not the home or away team wins.\n",
    "Unclear how good this actually is at characterizing teams. Should use team stats from as recent a metric as possible to reflect current gameplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.verbose =1\n",
    "model.batch_size = 20\n",
    "model.n_layers_ = 50\n",
    "model.n_outputs_= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "model.score(X_test,y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a raw version where I pull the last 5 stats of wiz vs pels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('predictionstuff.csv')\n",
    "data['3P%'] = np.divide(data['3P'].values,data['3PA'].values)\n",
    "del data['3P'],data['3PA']\n",
    "data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "del data['FG'],data['FGA']\n",
    "data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "del data['FT'],data['FTA'], data['2P'],data['2PA']\n",
    "data['ORB']= np.divide(data['ORB'].values,data['G'].values)\n",
    "data['DRB']= np.divide(data['DRB'].values,data['G'].values)\n",
    "data['TRB']= np.divide(data['TRB'].values,data['G'].values)\n",
    "data['TOV']= np.divide(data['TOV'].values,data['G'].values)\n",
    "data['BLK']= np.divide(data['BLK'].values,data['G'].values)\n",
    "data['AST']= np.divide(data['AST'].values,data['G'].values)\n",
    "data['STL']= np.divide(data['STL'].values,data['G'].values)\n",
    "data['PF']= np.divide(data['PF'].values,data['G'].values)\n",
    "del data['G']\n",
    "teams = data['Tm']\n",
    "del data['Tm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data[['ORB','DRB','TRB','AST','STL','BLK','TOV','PF','3P%','FG%','FT%']]\n",
    "data = data[[  'FG%'  ,'3P%' , 'ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK'  ,'FT%']]\n",
    "#team data is now lined up to be easily concatenated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lakers = data.values[21,:]\n",
    "nugs = data.values[18,:]\n",
    "kings = data.values[27,:]\n",
    "magic = data.values[25,:]\n",
    "cavs = data.values[17,:]\n",
    "clips = data.values[6,:]\n",
    "chi = data.values[16,:]\n",
    "det = data.values[4,:]\n",
    "bucks = data.values[8,:]\n",
    "por = data.values[12,:]\n",
    "wash = data.values[29,:]\n",
    "knicks = data.values[24,:]\n",
    "utah = data.values[14,:]\n",
    "grizz = data.values[7,:]\n",
    "atl = data.values[0,:]\n",
    "pacers = data.values[20,:]\n",
    "houston = data.values[5,:]\n",
    "raptors = data.values[28,:]\n",
    "heat = data.values[22,:]\n",
    "sixers = data.values[11,:]\n",
    "bos = data.values[15,:]\n",
    "wolves = data.values[23,:]\n",
    "nets = data.values[1,:]\n",
    "hornets = data.values[2,:]\n",
    "thunder = data.values[10,:]\n",
    "suns = data.values[26,:]\n",
    "spurs =data.values[13,:]\n",
    "dubs = data.values[19,:]\n",
    "pels = data.values[9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#omg1 = np.concatenate(ROADTEAM,HOMETEAM)\n",
    "\n",
    "ok = np.concatenate((suns,dubs))\n",
    "model.predict(np.array([ok]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = np.array(np.concatenate((ROADTEAM,HOMETEAM)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = np.array([np.concatenate((chi,det)),np.concatenate((dubs,por)),np.concatenate((suns,nets)),np.concatenate((houston,raptors)),np.concatenate((utah,grizz)),np.concatenate((knicks,bucks)),np.concatenate((lakers,nugs)),np.concatenate((magic,kings)),np.concatenate((wash,pels)),np.concatenate((cavs,clips))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/8 Games and if it was correct:\n",
    "\n",
    "Suns @ OKC YES\n",
    "\n",
    "Nets @ HOR NO\n",
    "\n",
    "Bos @ Min NO\n",
    "\n",
    "Phi @ Mia YES\n",
    "\n",
    "Sas @ GSW Says spurs, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start. What's left?\n",
    "\n",
    "1. What about assists, rebounds, steals, etc.? Can a table do that too? \n",
    "\n",
    "2. Hot encode wins and losses. Need to move that result column and delete everyhting except W and L.\n",
    "\n",
    "3. Normalize data?\n",
    "\n",
    "4. Create a net\n",
    "\n",
    "5. Figure out prediction data, go by season averages? L5 averages? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('expensive.csv',nrows=52) #nrows 52 because reader going to far otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneccesary stats. Flatten 2 adjascent rows because they're the same game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xfirst = np.concatenate((dat[:,0:8],dat[:,9:19]),axis=1) # + dat[:,20:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((Xfirst,dat[:,20:22]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(dat[:,0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "import pandas as pd\n",
    "\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.verbose =1\n",
    "model.batch_size = 2\n",
    "model.n_layers_ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(np.array([pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
