{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Going to predict the spreads for games on march 17th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import sys\n",
    "#import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#stderr = sys.stderr\n",
    "#sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(FILENAME):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as np\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \"\"\"Given the csv input of all the box scores, arrange it such that the home and away teams are lined up, \n",
    "    unnecessary columns removed, and proper hot encoding is done. Other stuff too probably.\n",
    "    \n",
    "    Note that this data has already been doctored from its original form, taking out most unnecessary columns but\n",
    "    those could be useful later on.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    FILENAME : file\n",
    "        The csv of the data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    X_train : array\n",
    "        Numpy array of the training inputs.\n",
    "    y_train : array\n",
    "        Numpy array of the training outputs.\n",
    "    \n",
    "    X_test : array\n",
    "        Numpy array of the testing inputs.\n",
    "    y_test : array\n",
    "        Numpy array of the testing outputs.\n",
    "    Sike!\n",
    "    \n",
    "    model : object\n",
    "        MLP which can predict the outcome of NBA games\n",
    "    \"\"\"\n",
    "    #Read in file, remove attempted and # and only account for % since that's more predictive in nature. \n",
    "    data = read_csv(FILENAME)\n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values)\n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['FT'],data['FTA']\n",
    "    data = get_dummies(data)\n",
    "    del data['VENUE_Home'],data['VENUE_Road']\n",
    "    #print(data)\n",
    "    \n",
    "    \n",
    "\n",
    "    dat = []\n",
    "\n",
    "    for i in range(len(data.values)):\n",
    "        data.values[i] = np.reshape(data.values[i],newshape=[1,len(data.values[i])])\n",
    "    for p in range(int(len(data.values)/2)):\n",
    "        fullboxgame = np.concatenate((data.values[2*p],data.values[(2*p)+1]))\n",
    "        dat.append(fullboxgame)\n",
    "    \n",
    "\n",
    "    \"\"\"At this point in the data dat is an array arranged as \n",
    "        OR  DR  TOT   A  PF  ST  TO  BL  PTS       3P%       FG%       FT% x2  (for road then home )\n",
    "    so next up is to hot pull road and home points \n",
    "    \n",
    "    road points is column 8 and home points is column 20. \n",
    "    \n",
    "    So grab those from dat and make y. \n",
    "    \n",
    "    X is every other column, so merge everyone else \n",
    "    \n",
    "    \"\"\"\n",
    "    dat = np.array(dat)   \n",
    "    roadpts = dat[:,8]\n",
    "\n",
    "    homepts = dat[:,21]\n",
    "    endspreadS = roadpts-homepts\n",
    "    openingspreadS = dat[:,9]\n",
    "#    print(\"opening spread:\" + str(dat[:,9]))\n",
    "    y = []\n",
    "    for j in range(len(endspreadS)):\n",
    "        openspread = openingspreadS[j]\n",
    "       # print(\"this is the spread of the road team \" + str(openspread))\n",
    "        endspread = endspreadS[j]\n",
    "       # print(\"the road team won by  .. \" + str(endspread))\n",
    "       # if endspread>openspread:\n",
    "        #    y.append(np.array([0,1,0]))  #OK, now make sure this is formateed properly!\n",
    "        if openspread + endspread <0:\n",
    "            y.append(np.array([0,1,0]))\n",
    "        elif openspread + endspread >0:\n",
    "            y.append(np.array([1,0,0]))\n",
    "        else: \n",
    "            y.append(np.array([0,0,1]))\n",
    "\n",
    "\n",
    "\n",
    "    y = np.array(y)\n",
    "    X1 = np.concatenate((dat[:,0:8],dat[:,10:21]),axis=1)\n",
    "    X = np.concatenate((X1,dat[:,23:26]),axis=1)    #need to go one further column to snag HFT% \n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(X,y,test_size=0.33)\n",
    "    #print((X[0]))\n",
    "    #print(np.shape(X[0]))\n",
    "    INPUT_DIM = len(X[0])\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30,input_dim=INPUT_DIM,activation='relu'))\n",
    "    model.add(Dense(30,input_dim=INPUT_DIM,activation='relu'))\n",
    "\n",
    "\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train,batch_size=32,epochs=20,validation_split=.2,verbose=1,)\n",
    "\n",
    "    print(model.evaluate(X_test,y_test))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If spread of road team is + that means they are supposed to lose by that much\n",
    "if the end spread is - that means the road team lost by that much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1406 samples, validate on 352 samples\n",
      "Epoch 1/20\n",
      "1406/1406 [==============================] - 0s 351us/step - loss: 2.5544 - acc: 0.5263 - val_loss: 0.9665 - val_acc: 0.5938\n",
      "Epoch 2/20\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.9286 - acc: 0.6430 - val_loss: 0.7588 - val_acc: 0.6619\n",
      "Epoch 3/20\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.7844 - acc: 0.6885 - val_loss: 0.7104 - val_acc: 0.6591\n",
      "Epoch 4/20\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.7049 - acc: 0.6984 - val_loss: 0.6505 - val_acc: 0.6989\n",
      "Epoch 5/20\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.6496 - acc: 0.7319 - val_loss: 0.6121 - val_acc: 0.7301\n",
      "Epoch 6/20\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.6203 - acc: 0.7376 - val_loss: 0.5864 - val_acc: 0.7500\n",
      "Epoch 7/20\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.5944 - acc: 0.7589 - val_loss: 0.6026 - val_acc: 0.7415\n",
      "Epoch 8/20\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.6044 - acc: 0.7518 - val_loss: 0.6549 - val_acc: 0.7074\n",
      "Epoch 9/20\n",
      "1406/1406 [==============================] - 0s 55us/step - loss: 0.5988 - acc: 0.7582 - val_loss: 0.5639 - val_acc: 0.7528\n",
      "Epoch 10/20\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.5685 - acc: 0.7824 - val_loss: 0.5727 - val_acc: 0.7614\n",
      "Epoch 11/20\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.5983 - acc: 0.7511 - val_loss: 0.6845 - val_acc: 0.6903\n",
      "Epoch 12/20\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.5725 - acc: 0.7639 - val_loss: 0.5921 - val_acc: 0.7528\n",
      "Epoch 13/20\n",
      "1406/1406 [==============================] - 0s 57us/step - loss: 0.6060 - acc: 0.7347 - val_loss: 0.5969 - val_acc: 0.7500\n",
      "Epoch 14/20\n",
      "1406/1406 [==============================] - 0s 58us/step - loss: 0.5514 - acc: 0.7703 - val_loss: 0.5789 - val_acc: 0.7557\n",
      "Epoch 15/20\n",
      "1406/1406 [==============================] - 0s 62us/step - loss: 0.5591 - acc: 0.7831 - val_loss: 0.5520 - val_acc: 0.7756\n",
      "Epoch 16/20\n",
      "1406/1406 [==============================] - 0s 60us/step - loss: 0.5465 - acc: 0.7752 - val_loss: 0.7496 - val_acc: 0.6477\n",
      "Epoch 17/20\n",
      "1406/1406 [==============================] - 0s 54us/step - loss: 0.5697 - acc: 0.7681 - val_loss: 0.7610 - val_acc: 0.6534\n",
      "Epoch 18/20\n",
      "1406/1406 [==============================] - 0s 68us/step - loss: 0.5624 - acc: 0.7802 - val_loss: 0.6047 - val_acc: 0.7301\n",
      "Epoch 19/20\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 0.5382 - acc: 0.773 - 0s 69us/step - loss: 0.5564 - acc: 0.7724 - val_loss: 0.6421 - val_acc: 0.7216\n",
      "Epoch 20/20\n",
      "1406/1406 [==============================] - 0s 59us/step - loss: 0.5534 - acc: 0.7745 - val_loss: 0.5816 - val_acc: 0.7528\n",
      "867/867 [==============================] - 0s 26us/step\n",
      "[0.5280571354095499, 0.7704728950403691]\n"
     ]
    }
   ],
   "source": [
    "noahbets = make_network('1517_boxscores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction_data(filename):\n",
    "    from pandas import read_csv,get_dummies\n",
    "    import numpy as xnp\n",
    "    from sklearn import cross_validation\n",
    "    data = read_csv(filename)\n",
    "    #convert to per game stats and sort columns. \n",
    "    data['ORB'] =  np.divide(data['ORB'].values,data['G'].values)\n",
    "    data['DRB'] =  np.divide(data['DRB'].values,data['G'].values)\n",
    "    data['TRB'] =  np.divide(data['TRB'].values,data['G'].values)\n",
    "    data['AST'] =  np.divide(data['AST'].values,data['G'].values)\n",
    "    data['STL'] =  np.divide(data['STL'].values,data['G'].values)\n",
    "    data['BLK'] =  np.divide(data['BLK'].values,data['G'].values)\n",
    "    data['TOV'] =  np.divide(data['TOV'].values,data['G'].values)\n",
    "    data['PF'] =  np.divide(data['PF'].values,data['G'].values)\n",
    "    teams  = data['Team']\n",
    "\n",
    "    data = data[['ORB' , 'DRB'  ,'TRB' ,  'AST' , 'PF' , 'STL' , 'TOV' , 'BLK' ,'3P%','FG%' ,'FT%']]\n",
    "    print(\"Here is every teams index value: \")\n",
    "    print(teams)\n",
    "    return teams,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_maker(roadteam,hometeam):\n",
    "    \"\"\"After creating a properly formated table, this concats the desired teams so they can be predicted. \n",
    "        Based on get team index # based on output of predictor, and make it the input for stats ie GSW are stats[0].\n",
    "        and so on!\n",
    "    \"\"\"\n",
    "    game = np.concatenate((roadteam,hometeam))\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is every teams index value: \n",
      "0     Golden State Warriors*\n",
      "1     Toronto Raptors*      \n",
      "2     Houston Rockets*      \n",
      "3     New Orleans Pelicans  \n",
      "4     Oklahoma City Thunder \n",
      "5     Minnesota Timberwolves\n",
      "6     Denver Nuggets        \n",
      "7     Cleveland Cavaliers   \n",
      "8     Los Angeles Lakers    \n",
      "9     Los Angeles Clippers  \n",
      "10    Washington Wizards    \n",
      "11    Charlotte Hornets     \n",
      "12    Philadelphia 76ers    \n",
      "13    Orlando Magic         \n",
      "14    Brooklyn Nets         \n",
      "15    Phoenix Suns          \n",
      "16    Indiana Pacers        \n",
      "17    Boston Celtics*       \n",
      "18    Portland Trail Blazers\n",
      "19    New York Knicks       \n",
      "20    Miami Heat            \n",
      "21    Atlanta Hawks         \n",
      "22    Milwaukee Bucks       \n",
      "23    Utah Jazz             \n",
      "24    Dallas Mavericks      \n",
      "25    San Antonio Spurs     \n",
      "26    Chicago Bulls         \n",
      "27    Detroit Pistons       \n",
      "28    Sacramento Kings      \n",
      "29    Memphis Grizzlies     \n",
      "30    League Average        \n",
      "Name: Team, dtype: object\n"
     ]
    }
   ],
   "source": [
    "teams, stats =make_prediction_data('teamstats_317.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.97101449, 34.04347826, 44.01449275, 23.91304348, 21.85507246,\n",
       "        8.01449275, 13.24637681,  6.04347826,  0.356     ,  0.47      ,\n",
       "        0.803     ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game1 = game_maker(stats.values[24],stats.values[14])\n",
    "game2 = game_maker(stats.values[27],stats.values[18])\n",
    "game3 = game_maker(stats.values[21],stats.values[22])\n",
    "game4 =  game_maker(stats.values[16],stats.values[10])\n",
    "game5 = game_maker(stats.values[2],stats.values[3])\n",
    "game6 = game_maker(stats.values[11],stats.values[19])\n",
    "game7 = game_maker(stats.values[7],stats.values[26])\n",
    "game8 = game_maker(stats.values[6],stats.values[29])\n",
    "game9 = game_maker(stats.values[5],stats.values[25])\n",
    "game10 =game_maker(stats.values[28],stats.values[23])\n",
    "game11 =game_maker(stats.values[0],stats.values[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7600634 , 0.2301049 , 0.00983162],\n",
       "       [0.64130557, 0.34647855, 0.01221585],\n",
       "       [0.69364244, 0.29266167, 0.01369589],\n",
       "       [0.7222185 , 0.26769456, 0.01008693],\n",
       "       [0.6267847 , 0.3654825 , 0.00773278],\n",
       "       [0.84223765, 0.15161434, 0.00614797],\n",
       "       [0.5907948 , 0.39573064, 0.01347451],\n",
       "       [0.85058016, 0.14037517, 0.0090446 ],\n",
       "       [0.6027452 , 0.38778976, 0.00946503],\n",
       "       [0.54237974, 0.44373718, 0.01388317],\n",
       "       [0.9197156 , 0.07308447, 0.00720002]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noahbets.predict(np.array([game1,game2,game3,game4,game5,game6,game7,game8,game9,game10,game11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winners 3/10:\n",
    "10 Hornets Y\n",
    "24 Heat Y\n",
    "27 Spurs N\n",
    "26 Mavs Y\n",
    "12 Clippers Y\n",
    "\n",
    "Winners 3/11:\n",
    "4 Raptors Y\n",
    "25 Bulls Y\n",
    "0 GSW N\n",
    "3 Pelicans N\n",
    "5 Nuggets Y\n",
    "26 Rockets Y\n",
    "13 Nets N\n",
    "7 Cavs N\n",
    "18 Celtics N\n",
    "\n",
    "Winners 3/12:\n",
    "Blazers Y\n",
    "Spurs N\n",
    "Bucks Y\n",
    "Thunder Y\n",
    "\n",
    "\n",
    "Winners 3/13:\n",
    "\n",
    "Philly N\n",
    "Wash N\n",
    "OKC Y\n",
    "Toronto Y\n",
    "Dallas Y\n",
    "Bulls N\n",
    "Pels Y\n",
    "Spurs Y\n",
    "UTAH Y\n",
    "Cle Y\n",
    "Lakers Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "20-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted winners on March 9th:\n",
    "\n",
    "Indiana\n",
    "Chicago \n",
    "toronto\n",
    "nop\n",
    "utah\n",
    "knicks    *\n",
    "lakers\n",
    "orlando  *\n",
    "warriors\n",
    "clippers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "20/29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrangement of Data:\n",
    "Away :      OR  DR  TOT   A  PF  ST  TO  BL  PTS   3P%       FG%       FT%\n",
    "  Home: OR  DR  TOT   A  PF  ST  TO  BL  3P%  FG%  FT%| AW HW\n",
    "      0    1   2   3   4   5  6    7   8    9   10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "1. Road Orbs\n",
    "2. Road Drbs\n",
    "3. Road Trbs\n",
    "4. Road Asts\n",
    "5. Road Pfs\n",
    "6. Road Stls\n",
    "7. Road Tos. \n",
    "8. Road Blks \n",
    "9. Road 3p%\n",
    "10. Road Fg%\n",
    "11. Road Ft% \n",
    "12. Road venue Home (0)  REMOVED\n",
    "13. Road venue Away (1) REMOVED\n",
    "14. Home Orbs\n",
    "15. Home Drbs\n",
    "16. Home Trbs\n",
    "17. Home Asts\n",
    "18. Home Pfs\n",
    "19. Home Stls\n",
    "20. Home Tos. \n",
    "21. Home Blks \n",
    "22. Home 3p%\n",
    "23. Home Fg%\n",
    "24. Home Ft% \n",
    "25. Home venue Home (0) REMOVED\n",
    "26. Home venue Away (1) REMOVED\n",
    "\n",
    "With Outputs \n",
    "\n",
    "27. Home team win (1)\n",
    "28. Road team win (0)\n",
    "\n",
    "\n",
    "So you enter the statistics of both teams, and it gives a classification of whether or not the home or away team wins.\n",
    "Unclear how good this actually is at characterizing teams. Should use team stats from as recent a metric as possible to reflect current gameplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a raw version where I pull the last 5 stats of wiz vs pels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/8 Games and if it was correct:\n",
    "\n",
    "Suns @ OKC YES\n",
    "\n",
    "Nets @ HOR NO\n",
    "\n",
    "Bos @ Min NO\n",
    "\n",
    "Phi @ Mia YES\n",
    "\n",
    "Sas @ GSW Says spurs, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start. What's left?\n",
    "\n",
    "1. What about assists, rebounds, steals, etc.? Can a table do that too? \n",
    "\n",
    "2. Hot encode wins and losses. Need to move that result column and delete everyhting except W and L.\n",
    "\n",
    "3. Normalize data?\n",
    "\n",
    "4. Create a net\n",
    "\n",
    "5. Figure out prediction data, go by season averages? L5 averages? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneccesary stats. Flatten 2 adjascent rows because they're the same game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
