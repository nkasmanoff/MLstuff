{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis on tweets for various companies, want to see how they're changing with time, and whether or not this is a good idea to choose where to throw $$\n",
    "\n",
    "Still need to confirm tweets are organized by date, that will be done tmrw\n",
    "\n",
    "\n",
    "The majority of this code is shamelessly stolen from:\n",
    "https://github.com/ciurana2016/predict_stock_py/blob/master/predict_stock.py\n",
    "\n",
    "AND \n",
    "\n",
    "https://github.com/Avhirup/Stock-Market-Prediction-Challenge/blob/master/Predicting%20Stock%20Prices%20Challenge.ipynb\n",
    "\n",
    "Thanks!\n",
    "\n",
    "Update: It appears there is an issue with downloading the stocks from NASDAQ, will check this out later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tweepy\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This I would prefer to grab from the web, continuously update\n",
    "#in a more convenient manner. \n",
    "data = pd.read_csv('SNAP.csv')\n",
    "\n",
    "#This doesn't work for now, let's just do it manually. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: \n",
    "\n",
    "Make a DNN, doesn't need to be recursive\n",
    "\n",
    "Use tweets to bolster if they line up and are positive, idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['High'], data['Low'], data['Adj Close'], data['Volume']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The openining price of one day is the input, and what it opens as the next day is the output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y =[]\n",
    "for p in range(len(dat)):\n",
    "    X.append([dat[p,1]])   #,dat[p,2]])\n",
    "    \n",
    "for q in range(len(dat)-1):\n",
    "    Y.append(dat[q+1,1])\n",
    "del X[-1]\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, Y, nb_epoch=200, batch_size=2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makenet(pricesnshit):\n",
    "    X = []\n",
    "    for i in range(len(pricesnshit)):\n",
    "        X.append(pricesnshit[i,1],pricesnshit(i,2))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "user = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_sentiment(quote, num_tweets):\n",
    "    # Checks if the sentiment for our quote is\n",
    "    # positive or negative, returns True if\n",
    "    # majority of valid tweets have positive sentiment\n",
    "    list_of_tweets = user.search(quote, count=num_tweets)\n",
    "    positive, null = 0, 0\n",
    "\n",
    "    for tweet in list_of_tweets:\n",
    "       # print(tweet.text)\n",
    "        #print(\"\")\n",
    "        blob = TextBlob(tweet.text).sentiment\n",
    "        if blob.subjectivity == 0:\n",
    "            null += 1\n",
    "            next\n",
    "        if blob.polarity > 0:\n",
    "            positive += 1\n",
    "\n",
    "    if positive > ((num_tweets - null)/2):\n",
    "        #if over half the tweets are considered positive polarity, this is good! \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_historical(quote):\n",
    "    # Download file from google finance\n",
    "    url = 'http://www.google.com/finance/historical?q=NASDAQ%3A'+quote+'&output=csv'\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    if r.status_code != 400:\n",
    "        with open(FILE_NAME, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_prediction():\n",
    "\n",
    "    # Collect data points from csv\n",
    "    dataset = []\n",
    "\n",
    "    with open(FILE_NAME) as f:\n",
    "        for n, line in enumerate(f):\n",
    "            if n != 0:\n",
    "                dataset.append(float(line.split(',')[1]))\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "\n",
    "    # Create dataset matrix (X=t and Y=t+1)\n",
    "    def create_dataset(dataset):\n",
    "        dataX = [dataset[n+1] for n in range(len(dataset)-2)]\n",
    "        return np.array(dataX), dataset[2:]\n",
    "        \n",
    "    trainX, trainY = create_dataset(dataset)\n",
    "\n",
    "    # Create and fit Multilinear Perceptron model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, nb_epoch=200, batch_size=2, verbose=1)\n",
    "\n",
    "    # Our prediction for tomorrow\n",
    "    prediction = model.predict(np.array([dataset[0]]))\n",
    "    result = 'The price will move from %s to %s' % (dataset[0], prediction[0][0])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_quote = input('Enter a stock quote from NASDAQ (e.j: AAPL, FB, GOOGL): ').upper()\n",
    "\n",
    "# Check if the stock sentiment is positve\n",
    "if not stock_sentiment(stock_quote, num_tweets=20):\n",
    "    print('This stock has bad sentiment, please re-run the script')\n",
    "    sys.exit()\n",
    "\n",
    "# Check if we got te historical data\n",
    "if not get_historical(stock_quote):\n",
    "    print('Google returned a 404, please re-run the script and')\n",
    "    print('enter a valid stock quote from NASDAQ')\n",
    "    sys.exit()\n",
    "\n",
    "# We have our file so we create the neural net and get the prediction\n",
    "print(stock_prediction())\n",
    "\n",
    "# We are done so we delete the csv file\n",
    "os.remove(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_sentiment('fit',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
